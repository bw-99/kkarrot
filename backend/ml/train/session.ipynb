{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2014-05-15</td>\n",
       "      <td>[15400, 8141, 26820, 39007]</td>\n",
       "      <td>[5.0, 5.0, 5.0, 5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2014-05-15</td>\n",
       "      <td>[8141, 26820, 39007, 4646]</td>\n",
       "      <td>[5.0, 5.0, 5.0, 3.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2014-12-06</td>\n",
       "      <td>[18665, 21455, 23236, 21297]</td>\n",
       "      <td>[5.0, 5.0, 5.0, 5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-02-11</td>\n",
       "      <td>[25341, 50734, 59076, 12715]</td>\n",
       "      <td>[4.0, 5.0, 2.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-02-11</td>\n",
       "      <td>[50734, 59076, 12715, 13616]</td>\n",
       "      <td>[5.0, 2.0, 2.0, 5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37260</th>\n",
       "      <td>1996</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>[31772, 76693, 49373, 47628]</td>\n",
       "      <td>[5.0, 2.0, 5.0, 5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37261</th>\n",
       "      <td>1998</td>\n",
       "      <td>2014-12-03</td>\n",
       "      <td>[27463, 5156, 28049, 24243]</td>\n",
       "      <td>[5.0, 5.0, 4.0, 5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37262</th>\n",
       "      <td>1998</td>\n",
       "      <td>2018-12-26</td>\n",
       "      <td>[57897, 83702, 54822, 55331]</td>\n",
       "      <td>[5.0, 5.0, 5.0, 5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37263</th>\n",
       "      <td>1998</td>\n",
       "      <td>2019-02-10</td>\n",
       "      <td>[55864, 57289, 55227, 55751]</td>\n",
       "      <td>[4.0, 4.0, 3.0, 5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37264</th>\n",
       "      <td>1998</td>\n",
       "      <td>2019-02-10</td>\n",
       "      <td>[57289, 55227, 55751, 60182]</td>\n",
       "      <td>[4.0, 3.0, 5.0, 5.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37265 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id        date                       item_id                rating\n",
       "0            0  2014-05-15   [15400, 8141, 26820, 39007]  [5.0, 5.0, 5.0, 5.0]\n",
       "1            0  2014-05-15    [8141, 26820, 39007, 4646]  [5.0, 5.0, 5.0, 3.0]\n",
       "2            0  2014-12-06  [18665, 21455, 23236, 21297]  [5.0, 5.0, 5.0, 5.0]\n",
       "3            0  2015-02-11  [25341, 50734, 59076, 12715]  [4.0, 5.0, 2.0, 2.0]\n",
       "4            0  2015-02-11  [50734, 59076, 12715, 13616]  [5.0, 2.0, 2.0, 5.0]\n",
       "...        ...         ...                           ...                   ...\n",
       "37260     1996  2020-01-28  [31772, 76693, 49373, 47628]  [5.0, 2.0, 5.0, 5.0]\n",
       "37261     1998  2014-12-03   [27463, 5156, 28049, 24243]  [5.0, 5.0, 4.0, 5.0]\n",
       "37262     1998  2018-12-26  [57897, 83702, 54822, 55331]  [5.0, 5.0, 5.0, 5.0]\n",
       "37263     1998  2019-02-10  [55864, 57289, 55227, 55751]  [4.0, 4.0, 3.0, 5.0]\n",
       "37264     1998  2019-02-10  [57289, 55227, 55751, 60182]  [4.0, 3.0, 5.0, 5.0]\n",
       "\n",
       "[37265 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "total_df = pd.read_pickle(\"../../data/processed/rating_engage.pkl\")\n",
    "rating_df = pd.read_pickle(\"../../data/processed/rating_session.pkl\")\n",
    "rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>item_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>556</td>\n",
       "      <td>2.0</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>843</td>\n",
       "      <td>2.0</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1039</td>\n",
       "      <td>5.0</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3865</td>\n",
       "      <td>5.0</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4646</td>\n",
       "      <td>3.0</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>60601</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>65713</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>16802</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>24396</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>21390</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>527772 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id item_id rating  item_len\n",
       "0           0     556    2.0        93\n",
       "0           0     843    2.0        93\n",
       "0           0    1039    5.0        93\n",
       "0           0    3865    5.0        93\n",
       "0           0    4646    3.0        93\n",
       "...       ...     ...    ...       ...\n",
       "1999     1999   60601      0       106\n",
       "1999     1999   65713      0       106\n",
       "1999     1999   16802      0       106\n",
       "1999     1999   24396      0       106\n",
       "1999     1999   21390      0       106\n",
       "\n",
       "[527772 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97718, 97717)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_df[\"item_id\"].unique()), total_df[\"item_id\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "item_sequences = rating_df['item_id'].tolist()  # item_id를 리스트로 변환\n",
    "user_ids = rating_df['user_id'].tolist()\n",
    "\n",
    "\n",
    "class SessionDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        return torch.tensor(sequence[:-1]), torch.tensor(sequence[-1])\n",
    "    \n",
    "train_data, test_data = train_test_split(item_sequences, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 128\n",
    "hidden_dim = 128\n",
    "num_epochs = 1000\n",
    "learning_rate = 5e-5\n",
    "batch_size = 512\n",
    "# 512 1e-4 0.4369\n",
    "# 512 53-5 0.4404\n",
    "\n",
    "train_loader = DataLoader(SessionDataset(train_data), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(SessionDataset(test_data), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from model import GRURecommender\n",
    "\n",
    "num_items = 368228\n",
    "\n",
    "model = GRURecommender(num_items, embedding_dim, hidden_dim).cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:03<00:00, 15.05it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 12.8200, Val Loss: 12.8141, Precision@20: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:03<00:00, 15.68it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/1000], Loss: 12.7674, Val Loss: 12.7977, Precision@20: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:03<00:00, 15.69it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/1000], Loss: 12.7124, Val Loss: 12.7802, Precision@20: 0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:03<00:00, 15.65it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/1000], Loss: 12.6515, Val Loss: 12.7609, Precision@20: 0.0378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:03<00:00, 15.18it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/1000], Loss: 12.5835, Val Loss: 12.7388, Precision@20: 0.0554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:03<00:00, 15.70it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/1000], Loss: 12.5051, Val Loss: 12.7130, Precision@20: 0.0710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:03<00:00, 15.67it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/1000], Loss: 12.4121, Val Loss: 12.6816, Precision@20: 0.0853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:03<00:00, 15.48it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/1000], Loss: 12.2978, Val Loss: 12.6415, Precision@20: 0.0996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:03<00:00, 15.66it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/1000], Loss: 12.1480, Val Loss: 12.5863, Precision@20: 0.1139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:03<00:00, 15.63it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 11.9366, Val Loss: 12.5028, Precision@20: 0.1304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:03<00:00, 15.16it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/1000], Loss: 11.6133, Val Loss: 12.3669, Precision@20: 0.1491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:03<00:00, 15.60it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/1000], Loss: 11.1107, Val Loss: 12.1739, Precision@20: 0.1761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:03<00:00, 15.60it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/1000], Loss: 10.4970, Val Loss: 12.0595, Precision@20: 0.2148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:03<00:00, 15.36it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/1000], Loss: 10.0463, Val Loss: 12.1073, Precision@20: 0.2555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:03<00:00, 15.55it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/1000], Loss: 9.8256, Val Loss: 12.1900, Precision@20: 0.2839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:03<00:00, 15.62it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/1000], Loss: 9.7065, Val Loss: 12.2484, Precision@20: 0.2900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:03<00:00, 15.68it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/1000], Loss: 9.6188, Val Loss: 12.2924, Precision@20: 0.2871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:03<00:00, 15.60it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/1000], Loss: 9.5460, Val Loss: 12.3296, Precision@20: 0.2859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:03<00:00, 15.94it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/1000], Loss: 9.4849, Val Loss: 12.3653, Precision@20: 0.2854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:03<00:00, 15.46it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/1000], Loss: 9.4272, Val Loss: 12.4015, Precision@20: 0.2843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:03<00:00, 15.49it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/1000], Loss: 9.3788, Val Loss: 12.4354, Precision@20: 0.2834\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "\n",
    "model_parameters = deepcopy(model.state_dict())\n",
    "\n",
    "def precision_at_k(preds, target, k=20):\n",
    "    top_k_preds = preds.topk(k, dim=1).indices.cpu().numpy()\n",
    "    target = target.cpu().numpy()\n",
    "    \n",
    "    y_true = np.isin(top_k_preds, target[:, None]) \n",
    "    y_pred = np.ones_like(y_true)  \n",
    "    \n",
    "    precision_scores = []\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        if np.sum(pred) == 0:  \n",
    "            precision_scores.append(0)\n",
    "        else:\n",
    "            precision_scores.append(precision_score(true, pred, zero_division=0))\n",
    "    return np.mean(precision_scores)\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, num_epochs, early_stopping_patience=5):\n",
    "    global model_parameters\n",
    "    best_val_precision = -float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for inputs, target in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.cuda())\n",
    "            loss = criterion(outputs, target.cuda())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.detach().cpu().item()\n",
    "\n",
    "        val_loss, val_precision = evaluate(model, val_loader, criterion)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Precision@20: {val_precision:.4f}')\n",
    "        \n",
    "        if val_precision > best_val_precision:\n",
    "            best_val_precision = val_precision\n",
    "            patience_counter = 0\n",
    "            model_parameters = deepcopy(model.state_dict())\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "def evaluate(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_precision = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, target in tqdm(data_loader):\n",
    "            outputs = model(inputs.cuda())\n",
    "            loss = criterion(outputs, target.cuda())\n",
    "            total_loss += loss.detach().cpu().item()\n",
    "            \n",
    "            total_precision += precision_at_k(outputs, target, k=20) * inputs.size(0)\n",
    "            total_samples += inputs.size(0)\n",
    "            \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    avg_precision = total_precision / total_samples\n",
    "    return avg_loss, avg_precision\n",
    "\n",
    "train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.248351796468098 0.29000402522474167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(model_parameters)\n",
    "\n",
    "avg_loss, avg_precision = evaluate(model, test_loader, criterion)\n",
    "print(avg_loss, avg_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"state_dict\": model.cpu().state_dict(),\n",
    "    \"num_items\": num_items,\n",
    "    \"embedding_dim\":embedding_dim,\n",
    "    \"hidden_dim\": hidden_dim\n",
    "}, \"../parameters/session.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyi_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
